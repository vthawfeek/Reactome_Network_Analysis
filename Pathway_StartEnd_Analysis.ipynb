{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start/End point analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code predicts start and end points in pathways based on network properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top-level pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 rows affected.\n",
      "13873 rows affected.\n",
      "Autophagy\n",
      "108 rows affected.\n",
      "131 rows affected.\n",
      "169 rows affected.\n",
      "Cell Cycle\n",
      "449 rows affected.\n",
      "467 rows affected.\n",
      "948 rows affected.\n",
      "Cell-Cell communication\n",
      "60 rows affected.\n",
      "25 rows affected.\n",
      "24 rows affected.\n",
      "Cellular responses to external stimuli\n",
      "260 rows affected.\n",
      "244 rows affected.\n",
      "395 rows affected.\n",
      "Chromatin organization\n",
      "85 rows affected.\n",
      "8 rows affected.\n",
      "374 rows affected.\n",
      "Circadian Clock\n",
      "59 rows affected.\n",
      "69 rows affected.\n",
      "64 rows affected.\n",
      "DNA Repair\n",
      "331 rows affected.\n",
      "322 rows affected.\n",
      "1430 rows affected.\n",
      "DNA Replication\n",
      "47 rows affected.\n",
      "45 rows affected.\n",
      "45 rows affected.\n",
      "Developmental Biology\n",
      "538 rows affected.\n",
      "460 rows affected.\n",
      "702 rows affected.\n",
      "Digestion and absorption\n",
      "30 rows affected.\n",
      "32 rows affected.\n",
      "29 rows affected.\n",
      "Disease\n",
      "1533 rows affected.\n",
      "954 rows affected.\n",
      "4209 rows affected.\n",
      "Extracellular matrix organization\n",
      "319 rows affected.\n",
      "297 rows affected.\n",
      "1286 rows affected.\n",
      "Gene expression (Transcription)\n",
      "997 rows affected.\n",
      "1098 rows affected.\n",
      "2775 rows affected.\n",
      "Hemostasis\n",
      "333 rows affected.\n",
      "269 rows affected.\n",
      "481 rows affected.\n",
      "Immune System\n",
      "1651 rows affected.\n",
      "1438 rows affected.\n",
      "4199 rows affected.\n",
      "Metabolism\n",
      "2245 rows affected.\n",
      "2391 rows affected.\n",
      "71229 rows affected.\n",
      "Metabolism of RNA\n",
      "189 rows affected.\n",
      "181 rows affected.\n",
      "262 rows affected.\n",
      "Metabolism of proteins\n",
      "892 rows affected.\n",
      "733 rows affected.\n",
      "2685 rows affected.\n",
      "Muscle contraction\n",
      "42 rows affected.\n",
      "22 rows affected.\n",
      "111 rows affected.\n",
      "Neuronal System\n",
      "216 rows affected.\n",
      "140 rows affected.\n",
      "602 rows affected.\n",
      "Organelle biogenesis and maintenance\n",
      "86 rows affected.\n",
      "76 rows affected.\n",
      "90 rows affected.\n",
      "Programmed Cell Death\n",
      "175 rows affected.\n",
      "233 rows affected.\n",
      "251 rows affected.\n",
      "Protein localization\n",
      "53 rows affected.\n",
      "49 rows affected.\n",
      "102 rows affected.\n",
      "Reproduction\n",
      "24 rows affected.\n",
      "22 rows affected.\n",
      "23 rows affected.\n",
      "Signal Transduction\n",
      "2400 rows affected.\n",
      "2445 rows affected.\n",
      "7258 rows affected.\n",
      "Transport of small molecules\n",
      "439 rows affected.\n",
      "165 rows affected.\n",
      "4324 rows affected.\n",
      "Vesicle-mediated transport\n",
      "252 rows affected.\n",
      "162 rows affected.\n",
      "486 rows affected.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cypher\n",
    "import os\n",
    "import re\n",
    "import networkx as nx\n",
    "\n",
    "#import predicted connection data\n",
    "##path\n",
    "notebook_path = os.path.abspath(\"Pathway_StartEnd_Analysis.ipynb\")\n",
    "path=notebook_path.rsplit('/',1)\n",
    "path1=path[0]+'/Reaction_Connectivity/'\n",
    "path2=path[0]+'/Integrative_Analysis/'\n",
    "path3=path[0]+'/Reaction_StartEnd/'\n",
    "\n",
    "Con=\"http://neo4j:reactome@localhost:7474/db/data\" #database connection\n",
    "\n",
    "#run query for pathway name-ID map\n",
    "PathwayName_ID_CQ=\"\"\"\n",
    "MATCH (tpa:TopLevelPathway{speciesName:\"Homo sapiens\"})\n",
    "RETURN tpa.displayName AS PathwayName, tpa.stId AS PathwayStId\n",
    "\"\"\" \n",
    "PathwayMap_DF=cypher.run(PathwayName_ID_CQ,conn=Con).get_dataframe()\n",
    "#TopPathwayMap_Dict=PathwayMap_DF.set_index('PathwayName')['TopPathwayName'].to_dict()\n",
    "PathwayMap_Dict=PathwayMap_DF.set_index('PathwayName')['PathwayStId'].to_dict()\n",
    "\n",
    "#run query for reaction ID-pathway map\n",
    "ReacPath_CQ=\"\"\"\n",
    "MATCH(pa:Pathway)-[:hasEvent]->(re:ReactionLikeEvent{speciesName:\"Homo sapiens\"})\n",
    "RETURN DISTINCT pa.displayName AS PathwayName, pa.stId AS PathwayID, re.displayName AS ReactionName, re.stId AS ReactionID\n",
    "\"\"\"\n",
    "ReacPathMap_DF=cypher.run(ReacPath_CQ,conn=Con).get_dataframe()\n",
    "ReacPathMap_Dict=ReacPathMap_DF.set_index('ReactionID')['PathwayName'].to_dict()\n",
    "ReacIDName_Dict=ReacPathMap_DF.set_index('ReactionID')['ReactionName'].to_dict()\n",
    "\n",
    "for i in sorted(PathwayMap_Dict):\n",
    "#for i in ['Circadian Clock']:\n",
    "\n",
    "    print(i)\n",
    "    \n",
    "    #assign pathway ID\n",
    "    Pathway_Name=i\n",
    "    Pathway_stId='\"'+PathwayMap_Dict[i]+'\"'\n",
    "\n",
    "    #run query for pathway-reaction map\n",
    "    PathReac_CQ=\"\"\"\n",
    "    MATCH(pa:Pathway{stId:\"\"\"+Pathway_stId+\"\"\"})-[:hasEvent*]->(re:ReactionLikeEvent{speciesName:\"Homo sapiens\"})\n",
    "    RETURN DISTINCT pa.displayName AS PathwayName, pa.stId AS PathwayID, re.displayName AS ReactionName, re.stId AS ReactionID\n",
    "    \"\"\"\n",
    "    PathReacMap_DF=cypher.run(PathReac_CQ,conn=Con).get_dataframe()\n",
    "    PathReacMap_Dict=PathReacMap_DF.set_index('ReactionID')['PathwayName'].to_dict()\n",
    "    \n",
    "    #run query to get precedingEvents connections\n",
    "    Preced_CQ=\"\"\"\n",
    "    MATCH(pa:Pathway{stId:\"\"\"+Pathway_stId+\"\"\"})-[:hasEvent*]->(ev:ReactionLikeEvent{speciesName:\"Homo sapiens\"})\n",
    "    MATCH(ev)-[:precedingEvent]->(pe:ReactionLikeEvent{speciesName:\"Homo sapiens\"})\n",
    "    RETURN DISTINCT pe.stId AS First_Reaction, ev.stId AS Second_Reaction\n",
    "    \"\"\"\n",
    "    Preced_DF=cypher.run(Preced_CQ,conn=Con).get_dataframe()\n",
    "\n",
    "    #run query to get reactions connected by shared entities\n",
    "    Shared_CQ=\"\"\"\n",
    "    ///query for non-set reactions\n",
    "    MATCH(pa1:Pathway{stId:\"\"\"+Pathway_stId+\"\"\"})-[:hasEvent*]->(ro1:ReactionLikeEvent{speciesName:\"Homo sapiens\"})-[:output]->(po1:PhysicalEntity)\n",
    "    WHERE NOT (po1.schemaClass=\"DefinedSet\" OR po1.schemaClass=\"CandidateSet\" OR po1.stId=\"R-HSA-113595\") //ignore Ub\n",
    "    WITH pa1, ro1, po1\n",
    "    MATCH(pa1)-[:hasEvent*]->(ri1:ReactionLikeEvent{speciesName:\"Homo sapiens\"})\n",
    "    WITH ro1, po1, ri1\n",
    "    MATCH(po1)<-[:input|catalystActivity|regulatedBy|regulator|physicalEntity*]-(ri1)\n",
    "    WITH ro1, ri1, po1\n",
    "    RETURN DISTINCT ro1.stId AS First_Reaction, ri1.stId AS Second_Reaction, po1.schemaClass AS SharedEntityClass, po1.displayName AS SharedEntityName, po1.stId AS SharedEntityID\n",
    "    ORDER BY ro1.stId\n",
    "    //query for set connectors\n",
    "    UNION MATCH(pa2:Pathway{stId:\"\"\"+Pathway_stId+\"\"\"})-[:hasEvent*]->(ro2:ReactionLikeEvent{speciesName:\"Homo sapiens\"})-[:output]->(po2a:PhysicalEntity)-[:hasMember|hasCandidate|physicalEntity*]->(po2b:PhysicalEntity)\n",
    "    WHERE (po2a.schemaClass=\"DefinedSet\" OR po2a.schemaClass=\"CandidateSet\") AND NOT (po2a.stId=\"R-HSA-113595\") //ignore Ub\n",
    "    WITH pa2, ro2, po2b\n",
    "    MATCH(pa2)-[:hasEvent*]->(ri2:ReactionLikeEvent{speciesName:\"Homo sapiens\"})\n",
    "    MATCH(po2b)<-[:input|catalystActivity|regulatedBy|regulator|physicalEntity|hasMember|hasCandidate*]-(ri2)\n",
    "    WITH ro2, ri2, po2b\n",
    "    RETURN DISTINCT ro2.stId AS First_Reaction, ri2.stId AS Second_Reaction, po2b.schemaClass AS SharedEntityClass, po2b.displayName AS SharedEntityName, po2b.stId AS SharedEntityID\n",
    "    ORDER BY ro2.stId\n",
    "    \"\"\"   \n",
    "    Pred_DF=cypher.run(Shared_CQ,conn=Con).get_dataframe()    \n",
    "    \n",
    "    #build network\n",
    "    ##create edges\n",
    "    Edges_DF = Preced_DF.copy(deep=True)\n",
    "    Pred_Rows_DF = Pred_DF[['First_Reaction','Second_Reaction']]\n",
    "    Edges_DF = Edges_DF.append(Pred_Rows_DF)\n",
    "    Edges_DF.drop_duplicates()\n",
    "    Edges_List = [(v['First_Reaction'],v['Second_Reaction'],0) for i,v in Edges_DF.iterrows() if v['First_Reaction'] in PathReacMap_Dict and v['Second_Reaction'] in PathReacMap_Dict] #remove reactions connecting other pathways\n",
    "    ##create nodes\n",
    "    Node_Set = set(PathReacMap_Dict)\n",
    "    ##create network\n",
    "    G=nx.MultiDiGraph()\n",
    "    G.add_nodes_from(Node_Set)\n",
    "    G.add_edges_from(Edges_List)\n",
    "    #nx.draw_spring(G)\n",
    "    \n",
    "    #check in and out degree\n",
    "    Indegree_Dict = {i:G.in_degree(i) for i in G.nodes}\n",
    "    Outdegree_Dict = {i:G.out_degree(i) for i in G.nodes}\n",
    "    ##sort degrees\n",
    "    Indegree_List = sorted(list(Indegree_Dict.keys()))\n",
    "    Outdegree_List = sorted(list(Outdegree_Dict.keys()))\n",
    "    ##print degrees\n",
    "    Indeg=set([i for i in Indegree_List if Indegree_Dict[i]==0 and Outdegree_Dict[i]>0])\n",
    "    Outdeg=set([i for i in Outdegree_List if Outdegree_Dict[i]==0 and Indegree_Dict[i]>0])\n",
    "#    print('No in degree (START) : ', Indeg, '\\nNo out degree (STOP):', Outdeg)\n",
    "    \n",
    "    Output_dict={}\n",
    "    #generate output list\n",
    "    ##creating equi-length start and end point lists\n",
    "    IndL = list(Indeg)\n",
    "    OutL = list(Outdeg)\n",
    "    if len(IndL)>len(OutL): OutL = OutL+['']*(len(IndL)-len(OutL))\n",
    "    if len(OutL)>len(IndL): IndL = IndL+['']*(len(OutL)-len(IndL))\n",
    "    ##creating output dictionary\n",
    "    Output_dict = {\n",
    "        'PathwayName':[Pathway_Name for i in IndL],\n",
    "        'StartPathwayName':[ReacPathMap_Dict[i]  if i!='' else '' for i in IndL],\n",
    "        'StartPoint': ['=HYPERLINK(\"https://reactome.org/content/detail/'+str(i)+'\",\"'+str(ReacIDName_Dict[i])+'\")' if i!='' else '' for i in IndL],\n",
    "        'EndPathwayName':[ReacPathMap_Dict[i]  if i!='' else '' for i in OutL],\n",
    "        'EndPoint': ['=HYPERLINK(\"https://reactome.org/content/detail/'+str(i)+'\",\"'+str(ReacIDName_Dict[i])+'\")'  if i!='' else '' for i in OutL]        \n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(Output_dict)\n",
    "    \n",
    "    #write outout to file\n",
    "    df.to_csv(path3+Pathway_Name+'_SE.csv',index=False,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All of Reactome "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13873 rows affected.\n",
      "60318 rows affected.\n",
      "11619 rows affected.\n",
      "103749 rows affected.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cypher\n",
    "import os\n",
    "import re\n",
    "import networkx as nx\n",
    "\n",
    "#import predicted connection data\n",
    "##path\n",
    "notebook_path = os.path.abspath(\"Pathway_StartEnd_Analysis.ipynb\")\n",
    "path=notebook_path.rsplit('/',1)\n",
    "path1=path[0]+'/Reaction_Connectivity/'\n",
    "path2=path[0]+'/Integrative_Analysis/'\n",
    "path3=path[0]+'/Reaction_StartEnd/'\n",
    "\n",
    "Con=\"http://neo4j:reactome@localhost:7474/db/data\" #database connection\n",
    "\n",
    "#run query for reaction ID-pathway map\n",
    "ReacPath_CQ=\"\"\"\n",
    "MATCH(pa:Pathway)-[:hasEvent]->(re:ReactionLikeEvent{speciesName:\"Homo sapiens\"})\n",
    "RETURN DISTINCT pa.displayName AS PathwayName, pa.stId AS PathwayID, re.displayName AS ReactionName, re.stId AS ReactionID\n",
    "\"\"\"\n",
    "ReacPathMap_DF=cypher.run(ReacPath_CQ,conn=Con).get_dataframe()\n",
    "ReacPathMap_Dict=ReacPathMap_DF.set_index('ReactionID')['PathwayName'].to_dict()\n",
    "ReacIDName_Dict=ReacPathMap_DF.set_index('ReactionID')['ReactionName'].to_dict()\n",
    "\n",
    "Pathway_Name = 'Reactome'\n",
    "\n",
    "#run query for pathway-reaction map\n",
    "PathReac_CQ=\"\"\"\n",
    "MATCH(pa:Pathway)-[:hasEvent*]->(re:ReactionLikeEvent{speciesName:\"Homo sapiens\"})\n",
    "RETURN DISTINCT pa.displayName AS PathwayName, pa.stId AS PathwayID, re.displayName AS ReactionName, re.stId AS ReactionID\n",
    "\"\"\"\n",
    "PathReacMap_DF=cypher.run(PathReac_CQ,conn=Con).get_dataframe()\n",
    "PathReacMap_Dict=PathReacMap_DF.set_index('ReactionID')['PathwayName'].to_dict()\n",
    "\n",
    "#run query to get precedingEvents connections\n",
    "Preced_CQ=\"\"\"\n",
    "MATCH(pa:Pathway)-[:hasEvent*]->(ev:ReactionLikeEvent{speciesName:\"Homo sapiens\"})\n",
    "MATCH(ev)-[:precedingEvent]->(pe:ReactionLikeEvent{speciesName:\"Homo sapiens\"})\n",
    "RETURN DISTINCT pe.stId AS First_Reaction, ev.stId AS Second_Reaction\n",
    "\"\"\"\n",
    "Preced_DF=cypher.run(Preced_CQ,conn=Con).get_dataframe()\n",
    "\n",
    "#run query to get reactions connected by shared entities\n",
    "Shared_CQ=\"\"\"\n",
    "///query for non-set reactions\n",
    "MATCH(pa1:Pathway)-[:hasEvent*]->(ro1:ReactionLikeEvent{speciesName:\"Homo sapiens\"})-[:output]->(po1:PhysicalEntity)\n",
    "WHERE NOT (po1.schemaClass=\"DefinedSet\" OR po1.schemaClass=\"CandidateSet\" OR po1.stId=\"R-HSA-113595\") //ignore Ub\n",
    "WITH pa1, ro1, po1\n",
    "MATCH(pa1)-[:hasEvent*]->(ri1:ReactionLikeEvent{speciesName:\"Homo sapiens\"})\n",
    "WITH ro1, po1, ri1\n",
    "MATCH(po1)<-[:input|catalystActivity|regulatedBy|regulator|physicalEntity*]-(ri1)\n",
    "WITH ro1, ri1, po1\n",
    "RETURN DISTINCT ro1.stId AS First_Reaction, ri1.stId AS Second_Reaction, po1.schemaClass AS SharedEntityClass, po1.displayName AS SharedEntityName, po1.stId AS SharedEntityID\n",
    "ORDER BY ro1.stId\n",
    "//query for set connectors\n",
    "UNION MATCH(pa2:Pathway)-[:hasEvent*]->(ro2:ReactionLikeEvent{speciesName:\"Homo sapiens\"})-[:output]->(po2a:PhysicalEntity)-[:hasMember|hasCandidate|physicalEntity*]->(po2b:PhysicalEntity)\n",
    "WHERE (po2a.schemaClass=\"DefinedSet\" OR po2a.schemaClass=\"CandidateSet\") AND NOT (po2a.stId=\"R-HSA-113595\") //ignore Ub\n",
    "WITH pa2, ro2, po2b\n",
    "MATCH(pa2)-[:hasEvent*]->(ri2:ReactionLikeEvent{speciesName:\"Homo sapiens\"})\n",
    "MATCH(po2b)<-[:input|catalystActivity|regulatedBy|regulator|physicalEntity|hasMember|hasCandidate*]-(ri2)\n",
    "WITH ro2, ri2, po2b\n",
    "RETURN DISTINCT ro2.stId AS First_Reaction, ri2.stId AS Second_Reaction, po2b.schemaClass AS SharedEntityClass, po2b.displayName AS SharedEntityName, po2b.stId AS SharedEntityID\n",
    "ORDER BY ro2.stId\n",
    "\"\"\"   \n",
    "Pred_DF=cypher.run(Shared_CQ,conn=Con).get_dataframe()    \n",
    "\n",
    "#build network\n",
    "##create edges\n",
    "Edges_DF = Preced_DF.copy(deep=True)\n",
    "Pred_Rows_DF = Pred_DF[['First_Reaction','Second_Reaction']]\n",
    "Edges_DF = Edges_DF.append(Pred_Rows_DF)\n",
    "Edges_DF.drop_duplicates()\n",
    "Edges_List = [(v['First_Reaction'],v['Second_Reaction'],0) for i,v in Edges_DF.iterrows() if v['First_Reaction'] in PathReacMap_Dict and v['Second_Reaction'] in PathReacMap_Dict]\n",
    "##create nodes\n",
    "Node_Set = set(PathReacMap_Dict)\n",
    "##create network\n",
    "G=nx.MultiDiGraph()\n",
    "G.add_nodes_from(Node_Set)\n",
    "G.add_edges_from(Edges_List)\n",
    "#nx.draw_spring(G)\n",
    "\n",
    "#check in and out degree\n",
    "Indegree_Dict = {i:G.in_degree(i) for i in G.nodes}\n",
    "Outdegree_Dict = {i:G.out_degree(i) for i in G.nodes}\n",
    "##sort degrees\n",
    "Indegree_List = sorted(list(Indegree_Dict.keys()))\n",
    "Outdegree_List = sorted(list(Outdegree_Dict.keys()))\n",
    "##print degrees\n",
    "Indeg=set([i for i in Indegree_List if Indegree_Dict[i]==0 and Outdegree_Dict[i]>0])\n",
    "Outdeg=set([i for i in Outdegree_List if Outdegree_Dict[i]==0 and Indegree_Dict[i]>0])\n",
    "#    print('No in degree (START) : ', Indeg, '\\nNo out degree (STOP):', Outdeg)\n",
    "\n",
    "Output_dict={}\n",
    "#generate output list\n",
    "##creating equi-length start and end point lists\n",
    "IndL = list(Indeg)\n",
    "OutL = list(Outdeg)\n",
    "if len(IndL)>len(OutL): OutL = OutL+['']*(len(IndL)-len(OutL))\n",
    "if len(OutL)>len(IndL): IndL = IndL+['']*(len(OutL)-len(IndL))\n",
    "##creating output dictionary\n",
    "Output_dict = {\n",
    "    'PathwayName':[Pathway_Name for i in IndL],\n",
    "    'StartPathwayName':[ReacPathMap_Dict[i]  if i!='' else '' for i in IndL],\n",
    "    'StartPoint': ['=HYPERLINK(\"https://reactome.org/content/detail/'+str(i)+'\",\"'+str(ReacIDName_Dict[i])+'\")' if i!='' else '' for i in IndL],\n",
    "    'EndPathwayName':[ReacPathMap_Dict[i]  if i!='' else '' for i in OutL],\n",
    "    'EndPoint': ['=HYPERLINK(\"https://reactome.org/content/detail/'+str(i)+'\",\"'+str(ReacIDName_Dict[i])+'\")'  if i!='' else '' for i in OutL]        \n",
    "}\n",
    "\n",
    "df = pd.DataFrame(Output_dict)\n",
    "\n",
    "#write outout to file\n",
    "df.to_csv(path3+Pathway_Name+'_SE.csv',index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
